{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNbBTiH2O0dv"
   },
   "source": [
    "# **Projet d'informatique**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXZZ-MXuCD3s"
   },
   "source": [
    "# Pré requis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA7ahJuB-V9e"
   },
   "source": [
    "## Importations des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jHyQ040Yqny",
    "outputId": "1140b367-ca52-4d69-f88f-edc5d8c72eea"
   },
   "outputs": [],
   "source": [
    "pip install https://github.com/matplotlib/mpl_finance/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzytgisVQFzP",
    "outputId": "fb3cb533-632b-46fc-b6d9-ca331ce61316"
   },
   "outputs": [],
   "source": [
    "!pip install pandas_datareader\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAQ5Z9IcX2gQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr   \n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib.dates import date2num\n",
    "from matplotlib.dates import DateFormatter, WeekdayLocator, DayLocator, MONDAY\n",
    "from mpl_finance import candlestick_ohlc\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIEpdw3QZ8li"
   },
   "source": [
    "## Définition des limites de temps : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-Cd7XUOYH5d"
   },
   "outputs": [],
   "source": [
    "start = datetime.datetime(2013,1,1)\n",
    "end = datetime.date.today()\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (15, 9) #taille des graphiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQ5GdMwI-0oJ"
   },
   "source": [
    "## Téléchargement des données du cac 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k_l2Lvf_BiU"
   },
   "outputs": [],
   "source": [
    "symbol_cac40={\"lvmh\":'MC.PA', \"danone\": 'BN.PA',\"thales\": 'HO.PA',\"airbus\": 'AIR.PA',\"total\": 'FP.PA',\"veolia\": 'VIE.PA',\\\n",
    "              \"societegenerale\": 'GLE.PA',\"vinci\": 'DG.PA',\"peugeot\": 'UG.PA',\"capgemini\": 'CAP.PA',\"axa\": 'CS.PA',\"safran\": 'SAF.PA',\\\n",
    "              \"Airliquide\": 'AI.PA',\"carrefour\": 'CA.PA',\"orange\": 'ORA.PA',\"accor\": 'AC.PA',\"bouygues\": 'EN.PA',\"worldline\": 'WLN.PA',\\\n",
    "              \"kering\": 'KER.PA',\"engie\": 'ENGI.PA',\"BNP\": 'BNP.PA',\"creditagricole\": 'ACA.PA',\"sanofi\": 'SAN.PA',\"pernodricard\": \"RI.PA\",\\\n",
    "              \"schneiderelectric\": 'SU.PA',\"l_oreal\": 'OR.PA',\"michelin\": 'ML.PA',\"vivendi\": 'VIV.PA',\"atos\": 'ATO.PA',\"sodexo\": 'SW.PA',\\\n",
    "              \"legrand\": 'LR.PA',\"saintgobain\": 'SGO.PA',\"arcelormittal\": 'MT.AS',\"dassault\": 'DSY.PA',\"essilorluxottica\": 'EL.PA',\\\n",
    "              \"hermes\": 'RMS.PA',\"publicis\": 'PUB.PA',\"technipfmc\": 'FTI.PA',\"unibail\": 'URW.AS',\"renault\": 'RNO.PA',\"stmicroelectronics\": 'STM.PA'}\n",
    "\n",
    "name_cac40 = [\"lvmh\", \"danone\",\"thales\",\"airbus\",\"total\",\"veolia\",\"societegenerale\",\"vinci\",\"peugeot\",\"capgemini\",\"axa\",\"safran\",\"Airliquide\",\\\n",
    "              \"carrefour\",\"orange\",\"accor\",\"bouygues\",\"worldline\",\"kering\",\"engie\",\"BNP\",\"creditagricole\",\"sanofi\",\"pernodricard\",\\\n",
    "              \"schneiderelectric\",\"l_oreal\",\"michelin\",\"vivendi\",\"atos\",\"sodexo\",\"legrand\",\"saintgobain\",\"arcelormittal\",\"dassault\",\\\n",
    "              \"essilorluxottica\",\"hermes\",\"publicis\",\"technipfmc\",\"unibail\",\"renault\",\"stmicroelectronics\"]\n",
    "\n",
    "cac40 = pdr.get_data_yahoo(\"^FCHI\", start, end)\n",
    "data_cac40 = {}\n",
    "\n",
    "for x in name_cac40 : \n",
    "    data_cac40[x] = pdr.get_data_yahoo(symbol_cac40[x],start=start, end=end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eveCdmoBrl3y",
    "outputId": "a59be062-2248-47a1-b62b-c4a18d12306c"
   },
   "outputs": [],
   "source": [
    "data_cac40.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnNM5hDdB5VY"
   },
   "source": [
    "## Diagramme à bougie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvuZIiOsBwu0"
   },
   "source": [
    "La fonction suivante nous permet de représenter les données brutes dans un diagramme à bougie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLFT9zb4aU53"
   },
   "outputs": [],
   "source": [
    "def pandas_candlestick_ohlc(dat, stick = \"day\", otherseries = None):\n",
    "    \"\"\"\n",
    "    :param dat: pandas DataFrame object with datetime64 index, and float columns \"Open\", \"High\", \"Low\", and \"Close\", likely created via DataReader \\\n",
    "    from \"yahoo\"\n",
    "    :param dat: un DataFrame de pandas avec une date type datetime64 et les colonnes de floats suivantes : \"Open\", \"High\", \"Low\", and \"Close\", \\\n",
    "    le plus souvent créées à partir du datareader de \"yahoo\"\n",
    "\n",
    "    :param stick: A string or number indicating the period of time covered by a single candlestick. Valid string inputs include \"day\", \"week\", \\\n",
    "    \"month\", and \"year\", (\"day\" default), and any numeric input indicates the number of trading days included in a period\n",
    "    :param stick: une chaine de caractères ou un nombre pour la période de temps couverte par une seule bougie. Les seules chaines de caractères \\\n",
    "    possibles sont  \"day\", \"week\", \"month\", et \"year\", (\"day\" par défault), et tous les autres floats qui indiquent le nombre de trades dans la \\\n",
    "    période.\n",
    "\n",
    "    :param otherseries: An iterable that will be coerced into a list, containing the columns of dat that hold other series to be plotted as lines\n",
    "    :param otherseries: un itérable de type liste qui contient les colonnes de dat pour les autres séries à plotter en lignes\n",
    "\n",
    "    This will show a Japanese candlestick plot for stock data stored in dat, also plotting other series if passed.\n",
    "    \n",
    "    Sort un graphique en bougie pour les dates stockées dans dat. \n",
    "    \"\"\"\n",
    "    mondays = WeekdayLocator(MONDAY)        # major ticks on the mondays\n",
    "    alldays = DayLocator()              # minor ticks on the days\n",
    "    dayFormatter = DateFormatter('%d')      # e.g., 12\n",
    "\n",
    "    # Create a new DataFrame which includes OHLC data for each period specified by stick input\n",
    "    transdat = dat.loc[:,[\"Open\", \"High\", \"Low\", \"Close\"]]\n",
    "    if (type(stick) == str):\n",
    "        if stick == \"day\":\n",
    "            plotdat = transdat\n",
    "            stick = 1 # Used for plotting\n",
    "        elif stick in [\"week\", \"month\", \"year\"]:\n",
    "            if stick == \"week\":\n",
    "                transdat[\"week\"] = pd.to_datetime(transdat.index).map(lambda x: x.isocalendar()[1]) # Identify weeks\n",
    "            elif stick == \"month\":\n",
    "                transdat[\"month\"] = pd.to_datetime(transdat.index).map(lambda x: x.month) # Identify months\n",
    "            transdat[\"year\"] = pd.to_datetime(transdat.index).map(lambda x: x.isocalendar()[0]) # Identify years\n",
    "            grouped = transdat.groupby(list(set([\"year\",stick]))) # Group by year and other appropriate variable\n",
    "            plotdat = pd.DataFrame({\"Open\": [], \"High\": [], \"Low\": [], \"Close\": []}) # Create empty data frame containing what will be plotted\n",
    "            for name, group in grouped:\n",
    "                plotdat = plotdat.append(pd.DataFrame({\"Open\": group.iloc[0,0],\n",
    "                                            \"High\": max(group.High),\n",
    "                                            \"Low\": min(group.Low),\n",
    "                                            \"Close\": group.iloc[-1,3]},\n",
    "                                           index = [group.index[0]]))\n",
    "            if stick == \"week\": stick = 5\n",
    "            elif stick == \"month\": stick = 30\n",
    "            elif stick == \"year\": stick = 365\n",
    "\n",
    "    elif (type(stick) == int and stick >= 1):\n",
    "        transdat[\"stick\"] = [np.floor(i / stick) for i in range(len(transdat.index))]\n",
    "        grouped = transdat.groupby(\"stick\")\n",
    "        plotdat = pd.DataFrame({\"Open\": [], \"High\": [], \"Low\": [], \"Close\": []}) # Create empty data frame containing what will be plotted\n",
    "        for name, group in grouped:\n",
    "            plotdat = plotdat.append(pd.DataFrame({\"Open\": group.iloc[0,0],\n",
    "                                        \"High\": max(group.High),\n",
    "                                        \"Low\": min(group.Low),\n",
    "                                        \"Close\": group.iloc[-1,3]},\n",
    "                                       index = [group.index[0]]))\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Valid inputs to argument \"stick\" include the strings \"day\", \"week\", \"month\", \"year\", or a positive integer')\n",
    "\n",
    "\n",
    "    # Set plot parameters, including the axis object ax used for plotting\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "    if plotdat.index[-1] - plotdat.index[0] < pd.Timedelta('730 days'):\n",
    "        weekFormatter = DateFormatter('%b %d')  # e.g., Jan 12\n",
    "        ax.xaxis.set_major_locator(mondays)\n",
    "        ax.xaxis.set_minor_locator(alldays)\n",
    "    else:\n",
    "        weekFormatter = DateFormatter('%b %d, %Y')\n",
    "    ax.xaxis.set_major_formatter(weekFormatter)\n",
    "\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Création du graphique en chandelier\n",
    "    candlestick_ohlc(ax, list(zip(list(date2num(plotdat.index.tolist())), plotdat[\"Open\"].tolist(), plotdat[\"High\"].tolist(),\n",
    "                      plotdat[\"Low\"].tolist(), plotdat[\"Close\"].tolist())),\n",
    "                      colorup = \"black\", colordown = \"red\", width = stick * .4)\n",
    "\n",
    "    # Plot other series (such as moving averages) as lines\n",
    "    if otherseries != None:\n",
    "        if type(otherseries) != list:\n",
    "            otherseries = [otherseries]\n",
    "        dat.loc[:,otherseries].plot(ax = ax, lw = 1.3, grid = True)\n",
    "\n",
    "    ax.xaxis_date()\n",
    "    ax.autoscale_view()\n",
    "    plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUtGOUqE77-Z"
   },
   "outputs": [],
   "source": [
    "def candlestick(ticker, start, end):\n",
    "    \n",
    "    df_ohlc = pdr.get_data_yahoo(ticker, start, end)[['Open','High','Low','Close']]\n",
    "    df_ohlc.reset_index(inplace=True)\n",
    "\n",
    "    fig = go.Figure(data=[go.Candlestick(x=df_ohlc['Date'],\n",
    "                    open=df_ohlc['Open'],\n",
    "                    high=df_ohlc['High'],\n",
    "                    low=df_ohlc['Low'],\n",
    "                    close=df_ohlc['Close'])])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "KsuhIs0y8Ave",
    "outputId": "5281f296-c5b0-4825-9cbd-5d238e925677"
   },
   "outputs": [],
   "source": [
    "candlestick('BNP.PA', start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6vpbMSDa0as"
   },
   "source": [
    "Dans un graphique à bougie : une bougie noire  représente un jour où le prix de fermeture était plus haut que le prix d'ouverture. Une bougie rouge représente un jour où le prix de fermeture était plus bas que l'ouverture.\n",
    "Le rectange représente l'ouverture et la fermeture, tandis que les \"mèches\" de la bougie représentent les points haut et bas de la journée. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQJXnAOfDrQP"
   },
   "source": [
    "# Représentation des données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "rUdy24Q8aef2",
    "outputId": "b5aab342-0779-4419-f0c6-0a913640375c"
   },
   "outputs": [],
   "source": [
    "stocks = pd.DataFrame({\"MC.PA\": data_cac40[\"lvmh\"][\"Adj Close\"],\n",
    "                       \"GLE.PA\": data_cac40[\"societegenerale\"][\"Adj Close\"],\n",
    "                       })\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "jAvHNfph_gPn",
    "outputId": "cf8cc48a-d774-48f5-f918-b556a5f34bfe"
   },
   "outputs": [],
   "source": [
    "stocks.plot(grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVQPdza_YIx_"
   },
   "source": [
    "Le problème d'un tel usage, est que les variations des deux cours ne sont pas bien représentées. Or ici c'est ce qui importe. Il faut donc représenter les cours sur deux échelles différentes pour mieux les observer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "AXEvmAbRclW4",
    "outputId": "38a404fd-7f7f-4c3f-ddae-26744ce9e640"
   },
   "outputs": [],
   "source": [
    "stocks.plot(secondary_y = [\"GLE.PA\"], grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eorHbwP7czqa"
   },
   "source": [
    "Une deuxième façon de faire, est de représenter les returns des cours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "QuU3-RUidAUt",
    "outputId": "e8dc14e2-9110-40a0-b855-541ce14921fb"
   },
   "outputs": [],
   "source": [
    "stock_return = stocks.apply(lambda x: np.log(x/x.shift(1)))\n",
    "stock_return.loc['2020-03-01':].plot(grid = True).axhline(y = 0, color = \"black\", lw = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_OL39I0b6Ix"
   },
   "outputs": [],
   "source": [
    "def bollinger_bands(name, start, end):\n",
    "    df = pdr.DataReader(name, 'yahoo', start, end)\n",
    "   \n",
    "    # On calcule la moyenne mobile 20, l'écart-type pour en déduire les bandes supérieures et inférieures\n",
    "    df['20 Day MA'] = df['Adj Close'].rolling(window=20).mean()\n",
    "    \n",
    "    df['20 Day STD'] = df['Adj Close'].rolling(window=20).std() \n",
    "    df['Upper Band'] = df['20 Day MA'] + (df['20 Day STD'] * 2)\n",
    "    df['Lower Band'] = df['20 Day MA'] - (df['20 Day STD'] * 2)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    x_axis = df.index.get_level_values(0)\n",
    "    \n",
    "    # On remplit l'espace séparant les bandes supérieures et inférieures des bandes de Bollinger\n",
    "    ax.fill_between(x_axis, df['Upper Band'], df['Lower Band'], color='grey')\n",
    "    \n",
    "    # On trace les prix ajustés de fermture et la moyenne mobile 20\n",
    "    ax.plot(x_axis, df['Adj Close'], color='blue', lw=2)\n",
    "    ax.plot(x_axis, df['20 Day MA'], color='r', lw=2)\n",
    "    \n",
    "    # Titre et présentation du graphe\n",
    "    ax.set_title('20 Day Bollinger Band For {}'.format(name))\n",
    "    ax.set_xlabel('Date (Year/Month)')\n",
    "    ax.set_ylabel('Price(USD)')\n",
    "    plt.grid(True)\n",
    "    ax.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "3apHb6VMcUxI",
    "outputId": "7442d7d9-340b-40dc-ddd6-0f76ce9044ca"
   },
   "outputs": [],
   "source": [
    "bollinger_bands('AAPL',start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kU9BLIjdiw_w"
   },
   "source": [
    "# Problème du Stock Split et Dividendes\n",
    "\n",
    "Les dividendes rajoutés au portefeuille et les entreprises qui rajoutent des actions sur le marché sont deux problèmes pouvant affecter le cours de l'action, et donc par conséquent notre profit tel qu'il est calculé. \n",
    "\n",
    "Il faut donc recalculer ceci en considérent le prix ajusté, que nous fournit Yahoo dans les données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4WZ9oinEGkd"
   },
   "outputs": [],
   "source": [
    "def ohlc_adj(dat):\n",
    "    \"\"\"\n",
    "    :param dat: pandas DataFrame de données brutes issues de Yahoo (\"Open\", \"High\", \"Low\", \"Close\", and \"Adj Close\")  \"Adj Close\" les prix de fermeture ajustés\n",
    "\n",
    "    :return: pandas DataFrame avec les données ajustées\n",
    "\n",
    "    Cette fonction règle le problème des splits, des dividendes etc. \n",
    "    Retourne un tableau semblable aux données de Yahoo, mais avec les données réelles. \n",
    "    \"\"\"\n",
    "    return pd.DataFrame({\"Open\": dat[\"Open\"] * dat[\"Adj Close\"] / dat[\"Close\"],\n",
    "                       \"High\": dat[\"High\"] * dat[\"Adj Close\"] / dat[\"Close\"],\n",
    "                       \"Low\": dat[\"Low\"] * dat[\"Adj Close\"] / dat[\"Close\"],\n",
    "                       \"Close\": dat[\"Adj Close\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYW-bkuXFH5F"
   },
   "source": [
    "Désormais, on appliquera à chaque fois ohlc_adj sur les données téléchargées de Yahoo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7oD_XPtdRge"
   },
   "source": [
    "# Méthode avec les Moyennes Mobiles Arithmétiques (MMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkgDI57cGUhS"
   },
   "source": [
    "## Calcul des moyennes mobiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "L70sW4WZ9KZO",
    "outputId": "59b96841-61bf-4c83-fb3d-e2f010cdf225"
   },
   "outputs": [],
   "source": [
    "lvmh_adj = ohlc_adj(data_cac40[\"lvmh\"])\n",
    "lvmh_adj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02ihDLHIdYrI"
   },
   "source": [
    "On calcule les moyennes mobiles sur un cours, avec des périodes caractéristiques de 20, 50, et 200 jours. (périodes les plus utilisées)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "viYURuP0dV_l",
    "outputId": "9e5cbf81-6950-4303-b0dc-7fb64f62d495"
   },
   "outputs": [],
   "source": [
    "lvmh_adj[\"20d\"] = lvmh_adj[\"Close\"].rolling(window = 20, center = False).mean()\n",
    "lvmh_adj[\"50d\"] = lvmh_adj[\"Close\"].rolling(window = 50, center = False).mean()\n",
    "lvmh_adj[\"200d\"] = lvmh_adj[\"Close\"].rolling(window = 200, center = False).mean()\n",
    "lvmh_adj.dropna(inplace=True)\n",
    "\n",
    "pandas_candlestick_ohlc(lvmh_adj.loc['2016-01-04':'2016-09-07',:], otherseries = [\"20d\", \"50d\", \"200d\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIsACNJduQt2"
   },
   "source": [
    "Concrètement, les moyennes mobiles représentent la tendance du marché avec plus ou moins de précisions selon le nombre de jours pris en compte dans le calcul de ces moyennes. En effet, on peut voir ci-dessus que la moyenne mobile 200 jours nous renseigne sur la tendance à long terme avec un fort lissage des variations. Les moyennes mobiles plus courtes nous informent des changements rapides de tendances. \n",
    "\n",
    "Lorsque la moyenne à 20 jours se trouve au dessus de celle à 50 jours, la tendance est haussière et inversement. Ce graphique vient confirmer cette théorie sur plusieurs périodes. \n",
    "\n",
    "Cette méthode est très populaire pour analyser simplement les tendances de marché. Cependant, il faudra également prendre en compte d'autres indicateurs pour appuyer nos prises de décision, c'est-à-dire l'achat, la vente, ou le maintien de notre position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR1q-YXbDLdK"
   },
   "source": [
    "## Trend Following Strategy\n",
    "\n",
    "On calcule la différence entre les moyennes mobiles courte (20d) et longue (50d). Cela nous permet de créer une variable de régime afin de savoir si l'on se trouve dans un régime haussier ou baissier.\n",
    "\n",
    "La méthode est la suivante : On produit un signal d'achat si la moyenne mobile 20 jours traverse la moyenne mobile 50 jours à la hausse et un signal de vente si elle la traverse à la baisse. Ce qui est important c'est le changement de signe de cette différence car il traduit l'entrée dans un nouveau régime (haussier ou baissier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esYUcSj4f_0s",
    "outputId": "5f643f45-9f81-4047-ad05-7af8aab78754"
   },
   "outputs": [],
   "source": [
    "lvmh_adj['20d-50d'] = lvmh_adj['20d'] - lvmh_adj['50d']\n",
    "\n",
    "lvmh_adj[\"Regime\"] = np.where(lvmh_adj['20d-50d'] > 0, 1, 0)\n",
    "lvmh_adj[\"Regime\"] = np.where(lvmh_adj['20d-50d'] < 0, -1, lvmh_adj[\"Regime\"])\n",
    "\n",
    "lvmh_adj[\"Regime\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 773
    },
    "id": "TmXwhWAp9UHP",
    "outputId": "8695013f-19bf-4e6b-bd16-bfff05b909f0"
   },
   "outputs": [],
   "source": [
    "lvmh_adj[\"Regime\"][-1] = 0\n",
    "\n",
    "# Création du signal à l'aide de la comparaison entre deux régimes successifs\n",
    "lvmh_adj[\"Signal\"] = np.sign(lvmh_adj[\"Regime\"] - lvmh_adj[\"Regime\"].shift(1))\n",
    "lvmh_adj.dropna(inplace=True)\n",
    "\n",
    "# Répresentation graphique des moyennes mobiles et des signaux qui en découlent\n",
    "lvmh_adj.loc['2016-01-04':'2017-09-07','Signal'].plot(figsize=(10,5))\n",
    "lvmh_adj.loc['2016-01-04':'2017-09-07',['Close', '20d', '50d']].plot(figsize=(10,5), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "pEOxaSbGjmVk",
    "outputId": "54702528-559c-4dcd-b9b2-3d4ca4bb74d8"
   },
   "outputs": [],
   "source": [
    "# On crée un tableau avec les opérations qui sont faites\n",
    "\n",
    "lvmh_adj_signals = pd.concat([pd.DataFrame({\"Price\": lvmh_adj.loc[lvmh_adj[\"Signal\"] == 1, \"Close\"],\n",
    "                                            \"Regime\":lvmh_adj.loc[lvmh_adj[\"Signal\"] == 1, \"Regime\"],\n",
    "                                            \"Signal\": \"Buy\"}),\n",
    "                              pd.DataFrame({\"Price\": lvmh_adj.loc[lvmh_adj[\"Signal\"] == -1, \"Close\"],\n",
    "                                            \"Regime\": lvmh_adj.loc[lvmh_adj[\"Signal\"] == -1, \"Regime\"],\n",
    "                                            \"Signal\": \"Sell\"}),])\n",
    "lvmh_adj_signals.sort_index(inplace = True)\n",
    "\n",
    "# J'enlève le premier ordre s'il s'agit d'une vente\n",
    "if lvmh_adj_signals[\"Signal\"][0] == \"Sell\" :\n",
    "    lvmh_adj_signals.drop(lvmh_adj_signals.index[0], inplace = True)\n",
    "\n",
    "lvmh_adj_signals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "c6eUJ90c9bFr",
    "outputId": "32fb7ac9-ff9f-4fbd-b45c-145b83f57dac"
   },
   "outputs": [],
   "source": [
    "# On crée un nouveau DataFrame comportant le prix au moment de l'achat, la date de vente et le profit réalisé au moment de celle-ci.\n",
    "lvmh_adj_long_profits = pd.DataFrame({\n",
    "    \"Price\": lvmh_adj_signals.loc[(lvmh_adj_signals[\"Signal\"] == \"Buy\") & lvmh_adj_signals[\"Regime\"] == 1, \"Price\"],\n",
    "    \n",
    "    \"Profit\": pd.Series(lvmh_adj_signals[\"Price\"] - lvmh_adj_signals[\"Price\"].shift(1)).loc[\n",
    "        lvmh_adj_signals.loc[(lvmh_adj_signals[\"Signal\"].shift(1) == \"Buy\") & (lvmh_adj_signals[\"Regime\"].shift(1) == 1)].index\n",
    "        ].tolist(),\n",
    "    \n",
    "    \"End Date\": lvmh_adj_signals[\"Price\"].loc[\n",
    "        lvmh_adj_signals.loc[(lvmh_adj_signals[\"Signal\"].shift(1) == \"Buy\") & (lvmh_adj_signals[\"Regime\"].shift(1) == 1)].index\n",
    "        ].index\n",
    "    })\n",
    "\n",
    "lvmh_adj_long_profits.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Sby2iPX2nXG",
    "outputId": "d46410b1-b5e2-41af-a3d6-d4d7268a9fc9"
   },
   "outputs": [],
   "source": [
    "lvmh_adj_long_profits['Profit'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qg5Ep9DKStV7"
   },
   "source": [
    "Le profit réalisé sur toute la période de trading, uniquement sur l'action LVMH, a été de 337 euros environ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsETcn0mTMLW"
   },
   "source": [
    "On reprend ci-dessous le même DataFrame que précédemment en y ajoutant le niveau le plus bas de l'action sur toute la période de trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "JV2sMLjAk_hI",
    "outputId": "419211b9-c274-4073-9acd-d1d9b1fdf4e5"
   },
   "outputs": [],
   "source": [
    "tradeperiods = pd.DataFrame({\"Start\": lvmh_adj_long_profits.index,\n",
    "                             \"End\": lvmh_adj_long_profits[\"End Date\"]})\n",
    "\n",
    "lvmh_adj_long_profits[\"Low\"] = tradeperiods.apply(lambda x: np.min(lvmh_adj.loc[x[\"Start\"]:x[\"End\"], \"Low\"]), axis = 1)\n",
    "\n",
    "lvmh_adj_long_profits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4dkIeK_lNzt"
   },
   "source": [
    "## Résultats de la stratégie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CppUlfHZTblk"
   },
   "source": [
    "Après avoir implémenté pas à pas la stratégie reposant sur les moyennes mobiles, nous allons maintenant la simuler complètement en nous imposant quelques contraintes cependant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxgqB-sJOY5Q"
   },
   "source": [
    "### Sur l'action LVMH seulement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "GRYBDwy0lUgL",
    "outputId": "2dc48dfe-e73f-4d53-ebd4-f635ed6d995b"
   },
   "outputs": [],
   "source": [
    "cash = 1000000\n",
    "lvmh_backtest = pd.DataFrame({\"Start Port. Value\": [],\n",
    "                              \"End Port. Value\": [],\n",
    "                              \"End Date\": [],\n",
    "                              \"Shares\": [],\n",
    "                              \"Share Price\": [],\n",
    "                              \"Trade Value\": [],\n",
    "                              \"Profit per Share\": [],\n",
    "                              \"Total Profit\": [],\n",
    "                              \"Stop-Loss Triggered\": []})\n",
    "\n",
    "port_value = .1  # Proportion max de la valeur de notre portefeuille que l'on engage lors d'une opération\n",
    "batch = 100      # Number of shares bought per batch\n",
    "stoploss = .2    # On arrêtera si on perd 20% de notre capital initial à un moment donné.\n",
    "\n",
    "for index, row in lvmh_adj_long_profits.iterrows():\n",
    "    batches = np.floor(cash * port_value) // np.ceil(batch * row[\"Price\"]) # Maximum number of batches of stocks invested in\n",
    "    trade_val = batches * batch * row[\"Price\"] # How much money is put on the line with each trade\n",
    "    if row[\"Low\"] < (1 - stoploss) * row[\"Price\"]:   # Account for the stop-loss\n",
    "        share_profit = np.round((1 - stoploss) * row[\"Price\"], 2)\n",
    "        stop_trig = True\n",
    "    else:\n",
    "        share_profit = row[\"Profit\"]\n",
    "        stop_trig = False\n",
    "    profit = share_profit * batches * batch # Compute profits\n",
    "    \n",
    "    # Add a row to the backtest data frame containing the results of the trade\n",
    "    lvmh_backtest = lvmh_backtest.append(pd.DataFrame({\"Start Port. Value\": cash,\n",
    "                                                       \"End Port. Value\": cash + profit,\n",
    "                                                       \"End Date\": row[\"End Date\"],\n",
    "                                                       \"Shares\": batch * batches,\n",
    "                                                       \"Share Price\": row[\"Price\"],\n",
    "                                                       \"Trade Value\": trade_val,\n",
    "                                                       \"Profit per Share\": share_profit,\n",
    "                                                       \"Total Profit\": profit,\n",
    "                                                       \"Stop-Loss Triggered\": stop_trig}, index = [index]))\n",
    "    cash = max(0, cash + profit)\n",
    "\n",
    "lvmh_backtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "lz9QaCf5-I-d",
    "outputId": "e5844907-226a-48cf-8983-d6e57e0c07ca"
   },
   "outputs": [],
   "source": [
    "lvmh_backtest[\"End Port. Value\"].plot(grid = True).axhline(y=1000000, color='red')\n",
    "plt.title(\"Résultat du Trend Following sur l'action LVMH\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEEfc5r_Od4O"
   },
   "source": [
    "### Sur un portefeuille diversifié ensuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxBDh7LsWIZq"
   },
   "source": [
    "On peut maintenant essayer d'appliquer cette stratégie sur un portefeuille composé de plusieurs actions, tout en gardant les mêmes contraintes que précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0tA-8fEmDVm"
   },
   "outputs": [],
   "source": [
    "def ma_crossover_orders(stocks, fast, slow):\n",
    "    \"\"\"\n",
    "    :param stocks: Une liste de tuples (Symbole de l'action, données brutes de Yahoo) \n",
    "    :param fast: Int pour le nombre de jours utilisé pour la moyenne mobile courte\n",
    "    :param slow: Int pour le nombre de jours utilisé pour la moyenne mobile longue\n",
    "\n",
    "    :return: pandas DataFrame contenant les ordres à passer\n",
    "\n",
    "    Cette fonction détermine quand chaque action doit être vendue ou achetée suivant la méthode des moyennes mobiles. \n",
    "    Pour chaque opération elle renvoie d'autres informations comme le cours de l'action à ce moment. \n",
    "    \"\"\"\n",
    "    fast_str = str(fast) + 'd'\n",
    "    slow_str = str(slow) + 'd'\n",
    "    ma_diff_str = fast_str + '-' + slow_str\n",
    "\n",
    "    trades = pd.DataFrame({\"Price\": [], \"Regime\": [], \"Signal\": []})\n",
    "    for s in stocks:\n",
    "        s[1][fast_str] = s[1][\"Close\"].rolling(window = fast, center = False).mean()\n",
    "        s[1][slow_str] = s[1][\"Close\"].rolling(window = slow, center = False).mean()\n",
    "        s[1][ma_diff_str] = s[1][fast_str] - s[1][slow_str]\n",
    "\n",
    "        s[1][\"Regime\"] = np.where(s[1][ma_diff_str] > 0, 1, 0)\n",
    "        s[1][\"Regime\"] = np.where(s[1][ma_diff_str] < 0, -1, s[1][\"Regime\"])\n",
    "        regime_orig = s[1][\"Regime\"][-1]\n",
    "        s[1][\"Regime\"][-1] = 0\n",
    "        s[1][\"Signal\"] = np.sign(s[1][\"Regime\"] - s[1][\"Regime\"].shift(1))\n",
    "        s[1][\"Regime\"][-1] = regime_orig\n",
    "\n",
    "\n",
    "        signals = pd.concat([pd.DataFrame({\"Price\": s[1].loc[s[1][\"Signal\"] == 1, \"Close\"],\n",
    "                                           \"Regime\": s[1].loc[s[1][\"Signal\"] == 1, \"Regime\"],\n",
    "                                           \"Signal\": \"Buy\"}),\n",
    "                             pd.DataFrame({\"Price\": s[1].loc[s[1][\"Signal\"] == -1, \"Close\"],\n",
    "                                           \"Regime\": s[1].loc[s[1][\"Signal\"] == -1, \"Regime\"],\n",
    "                                           \"Signal\": \"Sell\"}),\n",
    "                             ])\n",
    "        signals.index = pd.MultiIndex.from_product([signals.index, [s[0]]], names = [\"Date\", \"Symbol\"])\n",
    "        trades = trades.append(signals)\n",
    "\n",
    "    trades.sort_index(inplace = True)\n",
    "    trades.index = pd.MultiIndex.from_tuples(trades.index, names = [\"Date\", \"Symbol\"])\n",
    "\n",
    "    return trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KL7_ihJmHId"
   },
   "outputs": [],
   "source": [
    "def backtest(signals, cash, port_value = .1, batch = 100):\n",
    "    \"\"\"\n",
    "    :param signals: pandas DataFrame contenant les signaux d'achat/vente avec le symbole et le prix de ma_crossover_orders\n",
    "    :param cash: integer pour la valeur initiale investie\n",
    "    :param port_value: proportion maximale qu'on s'autorise à investir sur une opération\n",
    "    :param batch: nombre d'actions contenu dans un paquet que l'on peut acheter\n",
    "\n",
    "    :return: pandas DataFrame avec des résultats d'un backtest de la stratégie\n",
    "\n",
    "    On se servira dans cette fonction de l'historique de la valeur du portefeuille afin de voir comment il évolue dans le temps. \n",
    "    \"\"\"\n",
    "    SYMBOL = 1 \n",
    "    portfolio = dict()    \n",
    "    port_prices = dict()  \n",
    "\n",
    "    results = pd.DataFrame({\"Start Cash\": [],\n",
    "                            \"End Cash\": [],\n",
    "                            \"Portfolio Value\": [],\n",
    "                            \"Type\": [],\n",
    "                            \"Shares\": [],\n",
    "                            \"Share Price\": [],\n",
    "                            \"Trade Value\": [],\n",
    "                            \"Profit per Share\": [],\n",
    "                            \"Total Profit\": []})\n",
    "\n",
    "    for index, row in signals.iterrows():\n",
    "       \n",
    "        shares = portfolio.setdefault(index[SYMBOL], 0)\n",
    "        trade_val = 0\n",
    "        batches = 0\n",
    "        cash_change = row[\"Price\"] * shares   \n",
    "        portfolio[index[SYMBOL]] = 0  \n",
    "\n",
    "        old_price = port_prices.setdefault(index[SYMBOL], row[\"Price\"])\n",
    "        portfolio_val = 0\n",
    "        for key, val in portfolio.items():\n",
    "            portfolio_val += val * port_prices[key]\n",
    "\n",
    "        if row[\"Signal\"] == \"Buy\" and row[\"Regime\"] == 1:\n",
    "            batches = np.floor((portfolio_val + cash) * port_value) // np.ceil(batch * row[\"Price\"]) \n",
    "            trade_val = batches * batch * row[\"Price\"] \n",
    "            cash_change -= trade_val  \n",
    "            portfolio[index[SYMBOL]] = batches * batch  \n",
    "            port_prices[index[SYMBOL]] = row[\"Price\"] \n",
    "            old_price = row[\"Price\"]\n",
    "        elif row[\"Signal\"] == \"Sell\" and row[\"Regime\"] == -1: #a short\n",
    "            pass\n",
    "            \n",
    "        pprofit = row[\"Price\"] - old_price   \n",
    "\n",
    "        results = results.append(pd.DataFrame({\n",
    "                \"Start Cash\": cash,\n",
    "                \"End Cash\": cash + cash_change,\n",
    "                \"Portfolio Value\": cash + cash_change + portfolio_val + trade_val,\n",
    "                \"Type\": row[\"Signal\"],\n",
    "                \"Shares\": batch * batches,\n",
    "                \"Share Price\": row[\"Price\"],\n",
    "                \"Trade Value\": abs(cash_change),\n",
    "                \"Profit per Share\": pprofit,\n",
    "                \"Total Profit\": batches * batch * pprofit\n",
    "            }, index = [index]))\n",
    "        cash += cash_change  # Final change to cash balance\n",
    "\n",
    "    results.sort_index(inplace = True)\n",
    "    results.index = pd.MultiIndex.from_tuples(results.index, names = [\"Date\", \"Symbol\"])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "en_gSEbcRAZP"
   },
   "source": [
    "On applique notre strategie Trend Following sur un portefeuille diversifié de 10 actions. \n",
    "On utilise une somme d'argent de 1 000 000 d'euros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FqIZ9XIxmNSj",
    "outputId": "08a3b44e-35bd-40e0-bcb0-e910fecb72c5"
   },
   "outputs": [],
   "source": [
    "signals = ma_crossover_orders([(\"MC.PA\", ohlc_adj(data_cac40['lvmh'])),\n",
    "                              (\"BN.PA\",  ohlc_adj(data_cac40['danone'])),\n",
    "                              (\"HO.PA\",  ohlc_adj(data_cac40['thales'])),\n",
    "                              (\"AIR.PA\", ohlc_adj(data_cac40['airbus'])),\n",
    "                              (\"VIE.PA\",  ohlc_adj(data_cac40['veolia'])),\n",
    "                              (\"DG.PA\",   ohlc_adj(data_cac40['vinci'])),\n",
    "                              (\"UG.PA\", ohlc_adj(data_cac40['peugeot'])),\n",
    "                              (\"CAP.PA\",   ohlc_adj(data_cac40['capgemini'])),\n",
    "                              (\"CS.PA\",   ohlc_adj(data_cac40['axa'])),\n",
    "                              (\"SAF.PA\",   ohlc_adj(data_cac40['safran']))],\n",
    "                              fast = 20, slow = 50)\n",
    "\n",
    "bk = backtest(signals, 1000000)\n",
    "\n",
    "bk[\"Portfolio Value\"].groupby(level = 0).apply(lambda x: x[-1]).plot(grid=True).axhline(y=1000000, color='red')\n",
    "plt.title(\"Résultat du Trend Following sur un portefeuille diversifié\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0V0lPjJmx3W"
   },
   "source": [
    "# Méthode avec le MACD : un indicateur plus fiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdREo7Dst41_"
   },
   "source": [
    "On considère un nouvel indicateur : la MACD (Moving Average Convergence Divergence). \n",
    "\n",
    "Le MACD est calculé à partir des moyennes mobiles exponentielles (MME) 12 et MME 26.\n",
    "\n",
    "$MME_m(t) = \\alpha X_t + (1-\\alpha) MME_m(t-1)$   où    $\\alpha=\\frac{2}{m+1}$\n",
    "\n",
    "$MACD = MME_{12} - MME_{26}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-cb92bgmTxA"
   },
   "source": [
    "## Calcul de la MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "JUYbfyg_jh9F",
    "outputId": "97820ed3-edae-41b7-a024-0c374dc59686"
   },
   "outputs": [],
   "source": [
    "# On utilise la commande de pandas pandas.Series.ewm pour calculer des fonctions exponentielles pondérées\n",
    "# Création de la fonction qui va calculer la MACD\n",
    "def calcul_MACD(df):\n",
    "    \n",
    "    df['e26'] = pd.Series.ewm(df['Close'], span=26).mean() #Calcul de la moyenne mobile exponentielle 26\n",
    "    df['e12'] = pd.Series.ewm(df['Close'], span=12).mean() #Calcul de la moyenne mobile exponentielle 12\n",
    "    df['MACD'] = df['e12'] - df['e26'] # Calcul de la MACD\n",
    "    df['Signal line'] = pd.Series.ewm(df['MACD'], span=9).mean() #Calcul de la ligne de signal\n",
    "    return df\n",
    "\n",
    "# On applique cette fonction à notre DataFrame avec les données ajustées\n",
    "calcul_MACD(lvmh_adj).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xu0vqiDjn0rt"
   },
   "source": [
    "## Interprétation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAm8uX6QzpSj"
   },
   "source": [
    "### Interprétation 1 : croisement de la ligne de MACD et d'une une ligne de signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MMhU0Dkqik-"
   },
   "source": [
    "Il faut étudier les croisements de la MACD avec un signal. Bien souvent, on prend le signal défini par la moyenne mobile exponentielle sur x jours (**généralement 9**) de la ligne de MACD.\n",
    "\n",
    "Quand la ligne de MACD traverse à la hausse la ligne de signal, c'est un signal d'achat. A l'inverse quand la ligne de MACD traverse à la baisse la ligne de signal, c'est un signal de vente.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "LyRU9mfHsv8g",
    "outputId": "fd34eb23-2523-4c78-93d5-8261b6cd4b1d"
   },
   "outputs": [],
   "source": [
    "#Calcul du croisement de la ligne de MACD et de la ligne de signal\n",
    "lvmh_adj['MACD-Signal'] = lvmh_adj['MACD']-lvmh_adj['Signal line']\n",
    "lvmh_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "-gXEi7-OsvV4",
    "outputId": "da780460-e025-4e85-f2f4-a04871697b29"
   },
   "outputs": [],
   "source": [
    "# Visualisation des croisements de la ligne de MACD et de la ligne de signal :\n",
    "fig, (ax1,ax2) = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# Visualisation de la ligne de MACD et du signal\n",
    "ax1.plot(lvmh_adj.loc['2020-03-01':,'MACD'], label = 'MACD')\n",
    "ax1.plot(lvmh_adj.loc['2020-03-01':,'Signal line'], label = 'Signal', c='red')\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "ax1.set_title(\"Ligne de MACD et de signal\", fontsize=20)\n",
    "\n",
    "ax2.plot(lvmh_adj.loc['2020-03-01':, 'MACD-Signal'], label = \"MACD - MME9\")\n",
    "ax2.legend(loc='upper left')\n",
    "ax2.grid(True)\n",
    "ax2.set_title(\"Différence entre MACD et Signal\", fontsize=20)\n",
    "ax2.axhline(y=0, c='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leR95WLcxn__"
   },
   "source": [
    "Les pics \"positifs\" (respectivement \"négatifs\") de la courbe dans le deuxième graphique sont des signaux d'achat (respectivement de vente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ll--B37FzvXi"
   },
   "source": [
    "### Interprétation 2 : signe de la MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "UTg9Rzk-1xqE",
    "outputId": "4d0d8be6-a936-43d1-c1a2-63977b9a64b6"
   },
   "outputs": [],
   "source": [
    "# On prend un nouveau dataframe pour garder lvmh_adj clean\n",
    "very_new_lvmh_adj=lvmh_adj.copy()\n",
    "very_new_lvmh_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGhBj7jSzUfB"
   },
   "outputs": [],
   "source": [
    "# Fonction pour signaler l'achat ou la vente d'une action\n",
    "def buy_sell(df):\n",
    "  Buy = []\n",
    "  Sell = []\n",
    "  flag = -1\n",
    "\n",
    "  for i in range(0, len(df)):\n",
    "    if df['MACD'][i] > df['Signal line'][i] :\n",
    "      Sell.append(np.nan)\n",
    "      if flag != 1: #première fois qu'on passe par là\n",
    "        Buy.append(df['Close'][i])\n",
    "        flag = 1\n",
    "      else :\n",
    "        Buy.append(np.nan)\n",
    "    elif df['MACD'][i] < df['Signal line'][i] :\n",
    "      Buy.append(np.nan)\n",
    "      if flag != 0: #première fois qu'on passe par là\n",
    "        Sell.append(df['Close'][i])\n",
    "        flag = 0\n",
    "      else :\n",
    "        Sell.append(np.nan)\n",
    "    else :\n",
    "      Buy.append(np.nan)\n",
    "      Sell.append(np.nan)\n",
    "  \n",
    "  return Buy, Sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "sBZkQLVZ92fe",
    "outputId": "77088f18-77a8-4336-fee1-74bf62c00ad0"
   },
   "outputs": [],
   "source": [
    "# Création des colonnes représentant les signaux\n",
    "very_new_lvmh_adj['Buy_Signal_Price'] = buy_sell(very_new_lvmh_adj)[0]\n",
    "very_new_lvmh_adj['Sell_Signal_Price'] = buy_sell(very_new_lvmh_adj)[1]\n",
    "very_new_lvmh_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "ZVASbyu_-h__",
    "outputId": "d9101e92-87b7-46bd-8458-cae21b82278e"
   },
   "outputs": [],
   "source": [
    "#Visually show the stock buy and sell signal\n",
    "plt.figure()\n",
    "plt.scatter(very_new_lvmh_adj.index, very_new_lvmh_adj['Buy_Signal_Price'], color='green', label='Buy', marker='^', alpha=1)\n",
    "plt.scatter(very_new_lvmh_adj.index, very_new_lvmh_adj['Sell_Signal_Price'], color='red', label='Sell', marker='v', alpha=1)\n",
    "plt.plot(very_new_lvmh_adj['Close'], label = 'Close Price', alpha = 0.35)\n",
    "\n",
    "plt.title('Close Price Buy & Sells Signals')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price USD ($)')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ClharITw_T7"
   },
   "source": [
    "# Méthode avec le RSI : Relative Strength Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwnWHsNOrg_L"
   },
   "source": [
    "Le RSI est un indicateur qui permet de prévoir un changement de tendance, ou à défaut examine la force d'une tendance particulière.\n",
    "\n",
    "Le RSI mesure ainsi la force interne d'un titre, c'est à dire que l'on ne compare pas le titre à un indice.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsrhucYNc7of"
   },
   "source": [
    "\n",
    "\n",
    "##  Nature\n",
    "Le RSI est un indicateur compris entre 0 et 100. Comme son nom l'indique, il ne fait qu'interpréter une tendance en donnant une indication.\n",
    "- Si le RSI est compris vers 50 : \n",
    "C'est là qu'on observera le plus de changements de tendances car le marché se trouve dans un état d'équilibre sur la période de temps choisie. \n",
    "- Si le RSI est supérieur à 70 : Le marché est en sur-achat et il faut certainement prévoir un affaiblissement de la tendance correspondante.\n",
    "-  Si le RSI est inférieur à 30 : Le marché est en sur-vente et il faut certainement prévoir un affaiblissement de la tendance.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUJXL9rjc9Mf"
   },
   "source": [
    "## Exemple de stratégie de trading avec le RSI\n",
    "- Si le RSI dépasse 70 et qu'il revient couper 70 : cela peut signifier qu'une baisse ou des prises de bénéfices sont en cours et le trader aura tendance à vendre.\n",
    "- Si le RSI passe sous la barre des 30 puis revient la couper : cela peut singnifier qu'une hausse est en cours et le trader aura donc tendance à acheter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJfN6y7edF0k"
   },
   "source": [
    "## Calcul\n",
    "\n",
    "\n",
    "\n",
    "RSI = $100-\\frac{100}{1+\\frac{H}{B}}$\n",
    "\n",
    "- H est la moyenne des gains sur la période choisie (unité de temps) \n",
    "- B est la moyenne des baisses sur la période choisie (unité de temps)\n",
    "\n",
    "La valeur du RSI dépend donc de la méthode choisie pour calculer les moyennes, de la période sur laquelle on le calcule.\n",
    "\n",
    "Exemples : \n",
    "- RSI 9 sur un graphique en 2min : le RSI correspond à la moyenne sur les 2x9 = 18 dernières minutes. Donc en toute logique, si le trader achète avec ce RSI, il est prêt à maintenir cette position entre 2 et 18 minutes.\n",
    "- RSI 14 sur un graphique de 5min : Le RSI correspond à la moyenne sur les 70 dernières minutes.\n",
    "- RSI 25 sur un graphique en 1 journée : si le trader achète, il est prêt à investir sur les 25x1 prochaines journées.\n",
    "\n",
    "On fait ensuite le choix de calculer le RSI avec des moyennes mobiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdC6rqqSy0q2"
   },
   "outputs": [],
   "source": [
    "def RSI_mobile(stock, time):\n",
    "  \"\"\" Calcul du RSI en utilisant des moyennes mobiles\"\"\"\n",
    "  # On va moyenner sur les valeurs à la fermeture\n",
    "  close = stock['Close']\n",
    "  # Calcul de la différence avec la marche précédente\n",
    "  delta = close.diff()  \n",
    "  # On ne conserve que les time dernières lignes, sur lesquelles on veut calculer le RSI\n",
    "  delta = delta[1:]\n",
    "  # On veut une moyenne des hausses (H) et une moyenne des baisses (B)\n",
    "  up, down = delta.copy(), delta.copy() # On copie le DataFrame delta 2 fois dans les tables up et down\n",
    "  # On supprime les hausses de down et les baisses de up\n",
    "  up[up < 0] = 0 \n",
    "  down[down > 0] = 0 \n",
    "  # On calcule les moyennes arithmétiques respectives de up et down \n",
    "  H = up.rolling(time,center = False).mean()\n",
    "  B = down.rolling(time, center = False).mean().abs()\n",
    "  rsi = 100-(100/(1+H/B))\n",
    "  return rsi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "loXiNoYZBPDv",
    "outputId": "f4716d25-a9ce-4680-dca1-9c709ce5e340"
   },
   "outputs": [],
   "source": [
    "RSI_mobile(lvmh_adj[start:end], 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAcLJDeWyAKe"
   },
   "source": [
    "# Méthode avec le Stochastique\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCIYkfsG2AVs"
   },
   "source": [
    "##Présentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhcyHIkJ2Rvo"
   },
   "source": [
    "**Calcul**\n",
    "\n",
    "%$K=100 \\times \\frac{(Prix-de-cloture-actuel)  -  B_n}{H_n-B_n}$\n",
    "\n",
    "Avec $B_n$ pour le prix le plus bas et $H_n$ pour le prix le plus haut sur $n$ périodes (généralement 14 jours)\n",
    "\n",
    "\n",
    "\\\\\n",
    "%$D$ = la moyenne mobile de %$K$ sur $n$ périodes \n",
    "\n",
    "\\\\\n",
    "**Période : 14 jours**\n",
    "\n",
    " 1ère interprétation :\n",
    "Si le prix de clôture actuel est proche du prix le plus haut (Hn) de la période concerné, le Stochastique sera proche de 100%\n",
    "\n",
    "Si le prix de clôture actuel est proche du prix le plus bas (Bn) de la période concerné, le Stochastique sera proche de 0%\n",
    "\n",
    "Si la ligne %K atteint la zone des 80%, l'actif est considéré en surévaluation\n",
    "\n",
    "SI la ligne %D atteint la zone des 20%, l'actif est considéré en sous-évaluation\n",
    "\n",
    "**Croisement**\n",
    "\n",
    "Si la ligne %K croise par le haut la ligne %D, l'indicateur produit un signal d'achat.\n",
    "Si la ligne %K croise par le bas la ligne %D , l'indicateur produit un signal de vente.\n",
    "\n",
    "**Croisement avec la barre des 50%**\n",
    "\n",
    "Si la ligne %K croise par le haut la ligne horizontale du milieu, l'indicateur produit un signal d'achat.\n",
    "Si la ligne %K croise par le bas la ligne horizontale du milieu, l'indicateur produit un signal de vente.\n",
    "\n",
    "**Niveau de %K**\n",
    "\n",
    "Si la ligne %K se trouve au-dessus des 80%, alors un croisement à la baisse de la ligne horizontale haute (80%) produit un signal de vente.\n",
    "Si la ligne %K se trouve en-dessous des 20%, alors un croisement à la hausse de la ligne horizontale basse produit un signal d'achat.\n",
    "\n",
    "**Divergence **\n",
    "\n",
    "La divergence **haussière** se traduit par la formation de deux bas consécutifs du cours avec le bas le plus récent plus bas que son précédent tandis qu'au même moment, l'indicateur Stochastique réalise deux bas dont le plus récent est quant à lui plus haut que son bas précédent.\n",
    "La divergence baissière se traduit par la formation de deux sommets consécutifs avec le sommet le plus récent plus haut que son précédent tandis qu'au même moment, l'indicateur Stochastique MT4 réalise deux sommets dont le plus récent est quant à lui plus bas que son bas précédent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X70WGauZc-fe"
   },
   "source": [
    "## Calcul du stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "E7yYgYUOy1t1",
    "outputId": "4a7f2bc8-53e2-4540-b799-386155935a0c"
   },
   "outputs": [],
   "source": [
    "N = 14\n",
    "\n",
    "lvmh_adj[\"K\"] = 100*(lvmh_adj[\"Close\"]-lvmh_adj[\"Low\"].rolling(window = N).min())/(lvmh_adj[\"High\"].rolling(window = N).max()- lvmh_adj[\"Low\"].rolling(window = N).min())\n",
    "lvmh_adj[\"D\"] = lvmh_adj[\"K\"].rolling(window = N).mean()\n",
    "\n",
    "stochastique = pd.DataFrame({\"K\" : lvmh_adj[\"K\"],\n",
    "                             \"D\" : lvmh_adj[\"D\"]})\n",
    "\n",
    "stochastique.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "U8i-hR42nDlR",
    "outputId": "599b6a12-8004-4962-d71a-adf834107b72"
   },
   "outputs": [],
   "source": [
    "stochastique.loc['2019-10-02':end,:].plot(grid=True).axhline(y = 20, color = \"black\", lw = 2)\n",
    "plt.axhline(y=80, color = 'black', lw = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "jgajZxfOHJZH",
    "outputId": "47507395-b8be-4c0c-e434-7b8013c3932a"
   },
   "outputs": [],
   "source": [
    "lvmh_adj[\"K-80\"] = lvmh_adj[\"K\"] - 80\n",
    "lvmh_adj[\"K-50\"] = lvmh_adj[\"K\"] - 50\n",
    "lvmh_adj[\"K-20\"] = lvmh_adj[\"K\"] - 20\n",
    "lvmh_adj[\"K-D\"] = lvmh_adj[\"K\"] - lvmh_adj[\"D\"]\n",
    "\n",
    "lvmh_adj.dropna(inplace=True)\n",
    "lvmh_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RlC3Xlo6fpl",
    "outputId": "e898291e-0612-4735-c01c-5563fd3cd793"
   },
   "outputs": [],
   "source": [
    "#Note 0 : acheter et 5 : vendre\n",
    "\n",
    "def test_tab_bool(t1,t2):\n",
    "  t = t1.copy()\n",
    "  for i in range(len(t1)):\n",
    "    t[i] = t1[i] and t2[i]\n",
    "  return t\n",
    "\n",
    "# on met 5 si K < 20 et K traverse D à la hausse\n",
    "\n",
    "t = np.where(test_tab_bool(test_tab_bool((lvmh_adj[N+1:][\"K-D\"][1:]>0),(lvmh_adj[15:][\"K-D\"].shift(1)[1:]<0)), (lvmh_adj[15:][\"K-20\"].shift(1)[1:]<0)) ,5,2.5)\n",
    "lvmh_adj[\"Note\"] = np.concatenate((np.array((N+2)*[-1.]),t))\n",
    "\n",
    "\n",
    "# on met 0 si K>80 et K traverse D à la baisse\n",
    "t_2 = np.where(test_tab_bool((lvmh_adj[N+1:][\"K-D\"][1:]<0),test_tab_bool((lvmh_adj[N+1:][\"K-D\"].shift(1)[1:]>0),(lvmh_adj[N+1:][\"K-80\"].shift(1)[1:]>0))),0,lvmh_adj[N+2:][\"Note\"])\n",
    "lvmh_adj[\"Note\"] = np.concatenate((np.array((N+2)*[-1.]) ,t_2))\n",
    "\n",
    "lvmh_adj[\"Note\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2RbbpgadKny"
   },
   "source": [
    "## Résultats du stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9K7bmouhY2OD"
   },
   "outputs": [],
   "source": [
    "def ma_crossover_orders(stocks, bas, haut, N):\n",
    "    \"\"\"\n",
    "    :param stocks: Une liste de tuples (Symbole de l'action, données brutes de Yahoo) \n",
    "    :param bas: Int pour le seuil minimum que le stochastique peut franchir avant de considérer l'action en sur-vente\n",
    "    :param haut: Int pour le seuil maximum que le stochastique peut franchir avant de considérer l'action en sur-achat\n",
    "    :param N: Int pour la période du stochastique\n",
    "    :return: pandas DataFrame contenant les ordres à passer\n",
    "\n",
    "    Cette fonction détermine quand chaque action doit être vendue ou achetée suivant la méthode du stochastique.  \n",
    "    Pour chaque opération elle renvoie d'autres informations comme le couurs de l'action à ce moment. \n",
    "    \"\"\"\n",
    "    trades = pd.DataFrame({\"Price\": [], \"Regime\": [], \"Signal\": []})\n",
    "    for s in stocks:\n",
    "        s[1][\"K\"] = 100 *(s[1][\"Close\"]-s[1][\"Low\"].rolling(window=N).min())/(s[1][\"High\"].rolling(window = N).max()- s[1][\"Low\"].rolling(window = N).min())\n",
    "        s[1][\"D\"] = s[1][\"K\"].rolling(window=N).mean()\n",
    "\n",
    "        s[1][\"K-\"+str(haut)] = s[1][\"K\"] - haut\n",
    "        s[1][\"K-50\"] = s[1][\"K\"] -50\n",
    "        s[1][\"K-\"+str(bas)] = s[1][\"K\"] - bas\n",
    "        s[1][\"K-D\"] = s[1][\"K\"] - s[1][\"D\"]\n",
    "\n",
    "        # on met 5 si K <20 et K traverse D à la hausse\n",
    "        t = np.where(test_tab_bool(test_tab_bool((s[1][N+1:][\"K-D\"][1:]>0),(s[1][N+1:][\"K-D\"].shift(1)[1:]<0)), (s[1][N+1:][\"K-20\"].shift(1)[1:]<0)) ,5,2.5)\n",
    "        s[1][\"Note\"] = np.concatenate((np.array((N+2)*[-1.]),t))\n",
    "\n",
    "        # on met 0 si K>80 et K traverse D à la baisse\n",
    "        t_2 = np.where(test_tab_bool((s[1][N+1:][\"K-D\"][1:]<0),test_tab_bool((s[1][N+1:][\"K-D\"].shift(1)[1:]>0),(s[1][N+1:][\"K-80\"].shift(1)[1:]>0))),0,s[1][N+2:][\"Note\"])\n",
    "        s[1][\"Note\"] = np.concatenate((np.array((N+2)*[-1.]) ,t_2))\n",
    "\n",
    "        # Get signals\n",
    "        signals = pd.concat([\n",
    "            pd.DataFrame({\"Price\": s[1].loc[s[1][\"Note\"] == 5, \"Close\"],\n",
    "                          \"Regime\": s[1].loc[s[1][\"Note\"] == 5, \"Note\"],\n",
    "                          \"Signal\": \"Acheter\"}),\n",
    "            pd.DataFrame({\"Price\": s[1].loc[s[1][\"Note\"] == 0, \"Close\"],\n",
    "                          \"Regime\": s[1].loc[s[1][\"Note\"] == 0, \"Note\"],\n",
    "                          \"Signal\": \"Vendre\"}),\n",
    "        ])\n",
    "\n",
    "        signals.index = pd.MultiIndex.from_product([signals.index, [s[0]]], names = [\"Date\", \"Symbol\"])\n",
    "        trades = trades.append(signals)\n",
    "\n",
    "    trades.sort_index(inplace = True)\n",
    "    trades.index = pd.MultiIndex.from_tuples(trades.index, names = [\"Date\", \"Symbol\"])\n",
    "\n",
    "    return trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "HwC2rNniE-6g",
    "outputId": "c129a614-e956-40a6-abf2-e60631b9eff6"
   },
   "outputs": [],
   "source": [
    "def backtest(stocks, cash, portfolio = dict(),port_prices = dict()):\n",
    "    \"\"\"\n",
    "    :param stocks: Une liste de tuples (Symbole de l'action, données brutes de Yahoo)\n",
    "    :param cash: integer pour la valeur initiale investie\n",
    "    :param portfolio: dictionnaire avec les actions détenues\n",
    "    :param port_prices: dictionnaire avec le prix des actions détenues\n",
    "\n",
    "    :return: pandas DataFrame avec des résultats d'un backtest de la stratégie\n",
    "\n",
    "    On se servira dans cette fonction de l'historique de la valeur du portefeuille afin de voir comment il évolue dans le temps. \n",
    "    \"\"\"\n",
    "\n",
    "    signals = ma_crossover_orders(stocks, 20, 80, 14)\n",
    "\n",
    "    # Dataframe that will contain backtesting report\n",
    "    results = pd.DataFrame({\"Start Cash\": [],\n",
    "                            \"End Cash\": [],\n",
    "                            \"Portfolio Value\": [],\n",
    "                            \"Type\": [],\n",
    "                            \"Shares\": [],\n",
    "                            \"Share Price\": [],\n",
    "                            \"Trade Value\": [],\n",
    "                            \"Profit per Share\": [],\n",
    "                            \"Total Profit\": []})\n",
    "\n",
    "    for index, row in signals.iterrows():\n",
    "\n",
    "        #valeur du portefeuille avant l'opération\n",
    "        portfolio_val = 0 \n",
    "        for key, val in portfolio.items():\n",
    "            for i,dat in stocks :\n",
    "                if key ==i:\n",
    "                    port_prices[key] = dat.loc[str(index[0].date()),\"Close\"]\n",
    "            portfolio_val += val * port_prices[key]\n",
    "\n",
    "        shares = portfolio[index[1]]\n",
    "        old_price = port_prices[index[1]]\n",
    "        \n",
    "        n_max = np.floor((portfolio_val + cash)/(row[\"Price\"]*len(portfolio)))\n",
    "\n",
    "        if row[\"Signal\"]==\"Acheter\" and shares<n_max :\n",
    "            trade_val = (n_max-shares)*row[\"Price\"]\n",
    "            portfolio[index[1]]=n_max\n",
    "            port_prices[index[1]] = (shares*port_prices[index[1]]+(n_max-shares)*row[\"Price\"])/(n_max)\n",
    "            # Update report\n",
    "            results = results.append(pd.DataFrame({\n",
    "                    \"Start Cash\": cash,\n",
    "                    \"End Cash\": cash - trade_val,\n",
    "                    \"Portfolio Value\":cash + portfolio_val,\n",
    "                    \"Type\": row[\"Signal\"],\n",
    "                    \"Shares\": n_max - shares,\n",
    "                    \"Share Price\": row[\"Price\"],\n",
    "                    \"Trade Value\": trade_val,\n",
    "                    \"Profit per Share\": old_price - port_prices[index[1]],\n",
    "                    \"Total Profit\": (n_max - shares) * (old_price - port_prices[index[1]])\n",
    "                }, index = [index]))\n",
    "            cash -= trade_val\n",
    "\n",
    "    \n",
    "        elif row[\"Signal\"]==\"Vendre\" and shares > 0:\n",
    "            trade_val = shares * row[\"Price\"]\n",
    "            portfolio[index[1]]= 0\n",
    "            port_prices[index[1]] = row[\"Price\"]\n",
    "            # Update report\n",
    "            results = results.append(pd.DataFrame({\n",
    "                    \"Start Cash\": cash,\n",
    "                    \"End Cash\": cash + trade_val,\n",
    "                    \"Portfolio Value\":cash +portfolio_val,\n",
    "                    \"Type\": row[\"Signal\"],\n",
    "                    \"Shares\": shares ,\n",
    "                    \"Share Price\": row[\"Price\"],\n",
    "                    \"Trade Value\": trade_val,\n",
    "                    \"Profit per Share\": port_prices[index[1]],\n",
    "                    \"Total Profit\": shares* (port_prices[index[1]] - old_price)\n",
    "                }, index = [index]))\n",
    "            \n",
    "            cash += trade_val\n",
    "\n",
    "        else : pass \n",
    "\n",
    "    results.sort_index(inplace = True)\n",
    "    results.index = pd.MultiIndex.from_tuples(results.index, names = [\"Date\", \"Symbol\"])\n",
    "    return results\n",
    "\n",
    "end3 = datetime.datetime(2018,12,20)\n",
    "stocks = [(\"MC.PA\",ohlc_adj(data_cac40[\"lvmh\"])[end3:end]),\n",
    "                              (\"BN.PA\",ohlc_adj(data_cac40[\"danone\"])[end3:end]),\n",
    "                              (\"HO.PA\",ohlc_adj(data_cac40[\"thales\"])[end3:end]),\n",
    "                              (\"AIR.PA\",ohlc_adj(data_cac40[\"airbus\"])[end3:end]),\n",
    "                              (\"VIE.PA\",ohlc_adj(data_cac40[\"veolia\"])[end3:end]),\n",
    "                              (\"DG.PA\",ohlc_adj(data_cac40[\"vinci\"])[end3:end]),\n",
    "                              (\"UG.PA\",ohlc_adj(data_cac40[\"peugeot\"])[end3:end]),\n",
    "                              (\"CAP.PA\",ohlc_adj(data_cac40[\"capgemini\"])[end3:end]),\n",
    "                              (\"CS.PA\",ohlc_adj(data_cac40[\"axa\"])[end3:end]),\n",
    "                              (\"SAF.PA\",ohlc_adj(data_cac40[\"safran\"])[end3:end])]\n",
    "\n",
    "portfolio = {\"MC.PA\" : 0, \"BN.PA\" : 0,\"HO.PA\":0, \"AIR.PA\":0,\"VIE.PA\":0,\"DG.PA\":0,\"UG.PA\":0,\"CAP.PA\":0,\"CS.PA\":0,\"SAF.PA\":0}\n",
    "port_prices = {\"MC.PA\" : 0, \"BN.PA\" : 0,\"HO.PA\":0, \"AIR.PA\":0,\"VIE.PA\":0,\"DG.PA\":0,\"UG.PA\":0,\"CAP.PA\":0,\"CS.PA\":0,\"SAF.PA\":0}\n",
    "\n",
    "bk_sto = backtest(stocks, 100000, portfolio, port_prices) #commenté pour gagner du temps à compiler\n",
    "\n",
    "bk_sto[\"Portfolio Value\"].groupby(level = 0).apply(lambda x: x[-1]).plot(grid=True)\n",
    "plt.title(\"Résultat du stochastique sur une période d'un an\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "hyo-w_7oN95F",
    "outputId": "5e31f2eb-4be8-4d04-a3e1-7b2097ec8cb0"
   },
   "outputs": [],
   "source": [
    "bk[\"Start Cash\"].groupby(level = 0).apply(lambda x: x[-1]).plot(grid=True) \n",
    "plt.title(\"Evolution du cash disponible : celui qui n'est pas investi\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dce1YS3WalLh"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvpUCnu7a1fU"
   },
   "source": [
    "# Momentumn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "Tu0yAcqIankJ",
    "outputId": "d1ba052b-6fa5-4b6a-f5ec-0b8a7b3cd830"
   },
   "outputs": [],
   "source": [
    "N = 12\n",
    "\n",
    "lvmh_adj[\"momentum\"] = lvmh_adj[\"Close\"] - lvmh_adj[\"Close\"].shift(N)\n",
    "lvmh_adj[\"momentum\"].loc['2019-10-02':end].plot(grid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVWphOKG0HOZ"
   },
   "source": [
    "# CAPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiNhMjwN0Xlz"
   },
   "outputs": [],
   "source": [
    "risk_free_return = 0.05 #taux du livret A par exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8AVdE8o0PPa",
    "outputId": "c3159e92-5312-4a8a-94d1-1998eb2a7c19"
   },
   "outputs": [],
   "source": [
    "def capm(df1, df2, start, end):\n",
    "    \"\"\"\n",
    "    :param df1: pandas DataFrame de données brutes issues de Yahoo (\"Open\", \"High\", \"Low\", \"Close\", and \"Adj Close\")\n",
    "    :param df2: pandas DataFrame de données brutes issues de Yahoo (\"Open\", \"High\", \"Low\", \"Close\", and \"Adj Close\")\n",
    "    :param start: str de la première date de la période\n",
    "    :param end: str de la dernière date de la période\n",
    "    \n",
    "    :return: beta, CAPM\n",
    "    \n",
    "    Calcule le beta et le CAPM sur une période, à la date end. \n",
    "    CAPM = r_f + beta * (market_return - r_f)\n",
    "    \n",
    "    r_f : taux d'un placement sans risque : livret A en France\n",
    "    market_retun : rentabilité esperée du marché : rentabilité historique \n",
    "    beta : beta de l'actif financier df1\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    stock1 = df1[start:end]\n",
    "    stock2 = df2[start:end]\n",
    "\n",
    "    #On garde les lignes à une période d'un mois\n",
    "    return_s1 = stock1.resample('M').last()\n",
    "    return_s2 = stock2.resample('M').last()\n",
    "    \n",
    "    data = pd.DataFrame({'s_adjclose' : return_s1['Adj Close'], 'm_adjclose': return_s2['Adj Close']}, index=return_s1.index)\n",
    "    \n",
    "    data[['s_returns','m_returns']] = np.log(data[['s_adjclose', 'm_adjclose']]/data[['s_adjclose', 'm_adjclose']].shift(1))\n",
    "    \n",
    "    data = data.dropna() #on enlève les valeurs nulles\n",
    "\n",
    "    covmat = np.cov(data[\"s_returns\"], data[\"m_returns\"])\n",
    "    beta = covmat[0,1]/covmat[1,1]\n",
    "\n",
    "    return beta,risk_free_return + beta*(data[\"m_returns\"].mean()*12-risk_free_return)\n",
    "\n",
    "\n",
    "capm(data_cac40[\"lvmh\"], cac40, \"01 01 2016\", \"14 10 2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tab_capm(df,start,end):\n",
    "    \n",
    "    capm(df[\"Close\"][,cac40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLIHP4AR8KwF"
   },
   "source": [
    " # ML et trading\n",
    "\n",
    "1) Calculer des signaux d'achat que l'on juge correct pour servir de modèle pour un futur algorithme de trading : Préparation Feature Y\n",
    "\n",
    "2) Pas assez de données sur les valeurs Achat/Vente comparé au nombre de données sur la valeur Conserver. On fait de la Data Augmentation pour avoir les valeurs en nombre similaire. \n",
    "\n",
    "3) On prépare les features X, en séparant les données. Une partie pour l'entrainement (70%) et l'autre pour le test (30%)\n",
    "\n",
    "4) On applique un Random Forest Classifier sur nos données, et on visualise les résultats : Accuracy, Matrice de Confusion, et répartition de l'importance de chaque feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hI28FpVQ54z"
   },
   "source": [
    "## Importation des modules nécessaire\n",
    "\n",
    "Module *sklearn* pour le ML et module *sys* pour modifier la limite de récursion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDDdjHoFQ-fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from random import uniform\n",
    "\n",
    "sys.getrecursionlimit() #limite de récursion : elle est de 1000 par défaut, il faut plus de récursion puisqu'il en faut autant que le nb de ligne du tableau. \n",
    "# on change la limite à 3000\n",
    "sys.setrecursionlimit(3000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jwBguD_cf9K"
   },
   "source": [
    "## Préparation Feature Y\n",
    "\n",
    "Calculer des signaux d'achat entre **start** et **end** que l'on juge corrects pour servir de modèle pour un futur algorithme de trading : Préparation Feature Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4RHRzwZ8c79"
   },
   "outputs": [],
   "source": [
    "def training_set(data, results, start, end, alpha=0.0):\n",
    "    \"\"\"\n",
    "    Acheter : 2 ; Conserver : 1 ; Vendre : 0\n",
    "    \"\"\"\n",
    "    d = pd.Timedelta('1 day')\n",
    "    if len(results[start:end]) < 4:\n",
    "        try:\n",
    "            if data.loc[end, \"Close\"] > data.loc[start, \"Close\"]:\n",
    "                results.loc[start, \"Signal\"]= 2\n",
    "            else :\n",
    "                results.loc[end, \"Signal\"]= 2\n",
    "        except KeyError: #erreur si start n'est pas un jour ouvré\n",
    "            pass\n",
    "        return results\n",
    "\n",
    "    t = []\n",
    "    for index, row in data[end-7*d:end].iterrows():\n",
    "        t.append(index)\n",
    "    end_0 = t[-1]   # correspond à la dernière date du tableau\n",
    "    end_1 = t[-2]   # avant dernière date \n",
    "    end_2 = t[-3]   # avant avant dernière date \n",
    "    \n",
    "    i_m = data.loc[end_2:end_0,\"Close\"].idxmin()\n",
    "    i_M = data.loc[end_2:end_0,\"Close\"].idxmax()\n",
    "    m = data.loc[i_m, \"Close\"]\n",
    "    M = data.loc[i_M, \"Close\"]\n",
    "    if abs(m-M)>alpha*m : #condition de profit\n",
    "        if (i_m== end_2 and i_M == end_0) or (i_m== end_0 and i_M == end_2) :\n",
    "            results.loc[end_2:end_0,\"Signal\"] = 1  #on conserve car monotone sur l'intervalle de taille 3\n",
    "            return  training_set(data, results, start, end_1)\n",
    "\n",
    "        elif i_m == end_1: #le minimum est le point du milieu , inversion de tendance\n",
    "            results.loc[i_m,\"Signal\"] = 2 \n",
    "            return  training_set(data, results, start, end_1)\n",
    "        elif i_M == end_1: \n",
    "            results.loc[i_M,\"Signal\"] = 0 \n",
    "            return  training_set(data, results, start, end_1)\n",
    "  \n",
    "    else :  # pas de profit ici\n",
    "        results.loc[end_2:end_0,\"Signal\"] = 1 #on conserve car pas de profit réalisable\n",
    "        return  training_set(data, results, start, end_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YejBGlOcY3E"
   },
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Pas assez de données sur les valeurs Achat/Vente par rapport au nombre de données sur la valeur Conserver. On fait de la Data Augmentation pour avoir les valeurs en nombre similaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmGb1yuCtQ_e"
   },
   "outputs": [],
   "source": [
    "def data_augmentation(df,n=3,p=0.01):\n",
    "  \"\"\"\n",
    "  La valeur de p est très importante : c'est le pourcentage de modification. (Accuracy = 70% avec p=10%, =90% avec p=1%)\n",
    "  Objectif de cette fonction est de multiplier par 4 environ le nombre de valeur achat et vente\n",
    "  Donc à chaque fois qu'il y a une ligne dans df qui donne un signal vente ou achat, on en génère 3 autres. \n",
    "  Les 3 là doivent être des petites perturbations de la ligne initiale. \n",
    "  cette fonction sera appliquée à data à l'endroit indiqué ci dessous. à ce moment data a 0 : pour vendre, 1 pour conserver, 2 pour acheter\n",
    "\n",
    "  :param df: DataFrame avec les colonnes des indicateurs et une colonne avec le signal calculé par training_set\n",
    "  :param p: pourcentage de perturbation. \n",
    "\n",
    "  :return: DataFrame     comme df mais avec plus de lignes \n",
    "  \"\"\"\n",
    "  res = df.copy()\n",
    "  d = pd.Timedelta('1 day')\n",
    "  i=0\n",
    "  for index, row in df.iterrows():\n",
    "      if row[\"Signal\"]==0 or row[\"Signal\"]==2:\n",
    "          for j in range(n):\n",
    "              res = pd.concat([res, pd.DataFrame({\"MACD\" : row[0]*(1+uniform(-p,p)),\n",
    "                                        \"RSI\" : row[1]*(1+uniform(-p,p)),\n",
    "                                        \"STO_K\" : row[2]*(1+uniform(-p,p)),\n",
    "                                        \"D\" : row[3]*(1+uniform(-p,p)),\n",
    "                                        \"20d-50d\" :row[4]*(1+uniform(-p,p)),\n",
    "                                        \"momentum\" : row[5]*(1+uniform(-p,p)),\n",
    "                                        \"Signal\" : row[\"Signal\"]\n",
    "                                        },index = [end + i*d])])\n",
    "          i+=n\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tq8nSxox9_qy"
   },
   "source": [
    "##Préparation des features X\n",
    "\n",
    "On télécharge et prépare les features X, en séparant les données. Une partie pour l'entrainement (70%) et l'autre pour le test (30%)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Fv09bKD-FZ-"
   },
   "outputs": [],
   "source": [
    "def prepare(df,start=start, end = end,N=14):\n",
    "    \"\"\"\n",
    "    Permet de généraliser la préparation des données à n'importe quelle action, entrée en paramètre. \n",
    "\n",
    "    :param df: data brute téléchargée depuis Yahoo \n",
    "\n",
    "    :return: DataFrame avec les features X et Y(colonne \"Signal\")\n",
    "    \"\"\"\n",
    "    df = ohlc_adj(df[start:end]) #Cours ajusté\n",
    "\n",
    "    df[\"20d\"] = np.round(df[\"Close\"].rolling(window = 20, center = False).mean(), 2)\n",
    "    df[\"50d\"] = np.round(df[\"Close\"].rolling(window = 50, center = False).mean(), 2) \n",
    "    df[\"20d-50d\"] = df[\"20d\"] - df[\"50d\"]                                             \n",
    "    df = calcul_MACD(df)\n",
    "    df[\"e9\"] = pd.Series.ewm(df['MACD'], span=12).mean()\n",
    "\n",
    "    df[\"K\"] = 100 *(df[\"Close\"]-df[\"Low\"].rolling(window = N).min())/(df[\"High\"].rolling(window = N).max()- df[\"Low\"].rolling(window = N).min())\n",
    "    df[\"D\"] = df[\"K\"].rolling(window=3).mean()\n",
    "    df[\"momentum\"] = df[\"Close\"] - df[\"Close\"].shift(12)\n",
    "    \n",
    "    df[\"capm\"] = capm(df[\"Close\"], cac40, start, end)\n",
    "    \n",
    "    results = pd.DataFrame({\"Price\" : df[\"Close\"].copy(),\n",
    "                          \"Signal\" : 1})\n",
    "    results = training_set(df,results,start,end,0) \n",
    "\n",
    "    data = pd.DataFrame({\"MACD\" : df[\"MACD\"]-df[\"e9\"],\n",
    "                    \"RSI\" : RSI_mobile(df, N),\n",
    "                    \"STO_K\" : df[\"K\"],\n",
    "                    \"D\" : df[\"D\"],\n",
    "                    \"20d-50d\" : df[\"20d-50d\"],\n",
    "                    \"momentum\" : df[\"momentum\"],\n",
    "                    \"Signal\" : results[\"Signal\"]\n",
    "                    })[50:]\n",
    "    #on ne prend pas les 50 premières lignes car la colonne \"20d-50d\" contient NaN : pas applicable avec Random Forest\n",
    "    \n",
    "    return (data)\n",
    "\n",
    "end2 = datetime.datetime(2018,10,31)\n",
    "axa = pdr.get_data_yahoo('FP.PA',start=start, end=end2)\n",
    "data = prepare(axa,end=end2)\n",
    "\n",
    "# ici on applique la fonction data_augmentation(data)\n",
    "data2 = data_augmentation(data)\n",
    "\n",
    "X = data2[['MACD', 'RSI', 'STO_K', 'D', '20d-50d','momentum']]\n",
    "Y = data2[\"Signal\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09Qb5DsccrBT"
   },
   "source": [
    "## Random Forest Application\n",
    "\n",
    "On applique un Random Forest Classifier sur nos données, et on visualise les résultats : Accuracy, Matrice de Confusion, et répartition de l'importance de chaque feature.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "78ZOEpkeJ4aA",
    "outputId": "32ef89d5-b421-434e-c352-4f4b9eb0e016"
   },
   "outputs": [],
   "source": [
    "#Séparation des données en données d'entrainement(70%) et de données de test(30%) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "#Création de la fonction avec Random Forest\n",
    "\n",
    "clf=RandomForestClassifier(min_samples_leaf = 1, min_samples_split = 2, n_estimators=1500) # n : nombre d'arbres\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "feature_imp = pd.Series(clf.feature_importances_, index = [\"MACD\",'RSI', 'STO_K', \"D\", '20d-50d','momentum']).sort_values(ascending=False)\n",
    "\n",
    "#Matrice de confusion \n",
    "\n",
    "metrics.plot_confusion_matrix(clf, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(clf, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "XsHcIu561xZx",
    "outputId": "68b3e1c5-9c42-4c2d-910c-ad27ab4792d2"
   },
   "outputs": [],
   "source": [
    "# Mesure l'importance des features avec un histogramme\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "\n",
    "plt.xlabel(\"Scores de l'importance des features dans dans notre modèle\")\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualisation de l'importance des features\", fontsize=30)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIV1KaRXNYlb"
   },
   "source": [
    "# Corrélation des actions du portefeuille\n",
    "\n",
    "$\\underline{Idee}$ : Regarder les corrélations des actions du portefeuille en regroupant les actions les plus corrélées dans des familles.\n",
    "\n",
    "On appliquera le ML sur chaque famille pour tester l'hypothèse suivante : **\"l'entrainement de notre modèle sur un ensemble de données cohérentes renvoie un meilleur résultat\"**. \n",
    "\n",
    "On regarde la matrice de corrélation du cours des actions du CAC40 pour former des familles d'actions corrélées. Cette étape peut aussi être utile pour diversifier son portefeuille et éviter de ne suivre qu'une seule tendance si les actions de cette famille venaient à baisser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTDEryzplnw7"
   },
   "outputs": [],
   "source": [
    "# Création d'un DataFrame avec en colonne les actions du cac40 et avec les indicateurs économiques en ligne.\n",
    "\n",
    "\n",
    "stocks_cac40 = pd.DataFrame({x : data_cac40[x][\"Adj Close\"] for x in name_cac40})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWwVAm0bZhsm"
   },
   "outputs": [],
   "source": [
    "#dict_stocks_cac40={\"lvmh\":lvmh, \"danone\": danone,\"thales\": thales,\"airbus\": airbus,\"total\": total,\"veolia\": veolia,\"so_ge\": societegenerale,\"vinci\": vinci,\"peugeot\": peugeot,\"capge\": capgemini,\"axa\": axa,\"safran\": safran,\"Airliq\": airliquide,\"CARF\": carrefour,\"orange\": orange,\"accor\": accor,\"bouygues\": bouygues,\"WORLDL\": worldline,\"kering\": kering,\"engie\": engie,\"BNP\": bnp,\"CA\": creditagricole,\"sanofi\": sanofi,\"pernod\": pernodricard,\"schneid\": schneiderelectric,\"l_oreal\": loreal,\"michelin\": michelin,\"vivendi\": vivendi,\"atos\": atos,\"sodexo\": sodexo,\"legrand\": legrand,\"St_Gob\": saintgobain,\"arcelor\": arcelormittal,\"dassault\": dassault,\"essilor\": essilorluxottica,\"hermes\": hermes,\"publicis\": publicis,\"technip\": technipfmc,\"unibail\": unibail,\"renault\": renault,\"STM\": stmicroelectronics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 797
    },
    "id": "j6J7KnYw33xX",
    "outputId": "0c405337-20c9-4bee-da71-fcd98fb52b82"
   },
   "outputs": [],
   "source": [
    "# MATRICE DE CORRELATIONS = HEAT MAP\n",
    "\n",
    "f = plt.figure(figsize=(15, 12))\n",
    "plt.matshow(stocks_cac40.corr(), fignum=f.number)\n",
    "plt.xticks(range(stocks_cac40.shape[1]), stocks_cac40.columns, fontsize=9.5, rotation=45)\n",
    "plt.yticks(range(stocks_cac40.shape[1]), stocks_cac40.columns, fontsize=9.5)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=12)\n",
    "plt.title('Matrice de corrélation', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YkOCWzhngdO"
   },
   "outputs": [],
   "source": [
    "cac ={\"lvmh\":clf, \"danone\": clf,\"thales\": clf,\"airbus\": clf,\"total\": clf,\"veolia\": clf,\"so_ge\": clf,\"vinci\": clf,\"peugeot\": clf,\"capge\": clf,\"axa\": clf,\"safran\": clf,\"Airliq\": clf,\"CARF\": clf,\"orange\": clf,\"accor\": clf,\"bouygues\": clf,\"WORLDL\": clf,\"kering\": clf,\"engie\": clf,\"BNP\": clf,\"CA\": clf,\"sanofi\": clf,\"pernod\": clf,\"schneid\": clf,\"l_oreal\": clf,\"michelin\": clf,\"vivendi\": clf,\"atos\": clf,\"sodexo\": clf,\"legrand\": clf,\"St_Gob\": clf,\"arcelor\": clf,\"dassault\": clf,\"essilor\": clf,\"hermes\": clf,\"publicis\": clf,\"technip\": clf,\"unibail\": clf,\"renault\": clf,\"STM\": clf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JllC39sW6nx"
   },
   "source": [
    "## Construction des familles\n",
    "\n",
    "On va ensuite s'atteler à la création des familles à partir des corrélations que les actions peuvent avoir entre elles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9he9BiYbg0p"
   },
   "outputs": [],
   "source": [
    "# On crée deux matrices de corrélation \n",
    "# L'une nous sert à sélectionner les différentes actions selon leur corrélation\n",
    "mat_corr = stocks_cac40.corr().copy()\n",
    "\n",
    "# L'autre est immuable, et permet de ne sélectionner qu'une seule et unique fois chaque action\n",
    "mat_corr_immu = stocks_cac40.corr().copy()\n",
    "\n",
    "\n",
    "# liste qui contiendra les différentes familles\n",
    "family = [[] for k in range(41)]\n",
    "\n",
    "# On crée une liste avec le nom des actiosn pour relier un indice à un nom d'action\n",
    "liste_actions = []\n",
    "for corr in mat_corr:\n",
    "  liste_actions.append(corr)\n",
    "liste_actions\n",
    "\n",
    "# Compteur pour n'avoir qu'une famille par action\n",
    "S = 41\n",
    "\n",
    "# Dictionnaire des indices de la matrice de corrélation immuable qu'on videra au fur et à mesure qu'une action sera choisie  (une liste verrait ses indices modifiés)\n",
    "liste_index = {k:k for k in range(0,S)}\n",
    "\n",
    "for num_ligne in range(0,S):\n",
    "  if not num_ligne in liste_index:\n",
    "    continue \n",
    "  for num_colonne in range(0,S):\n",
    "    if not num_colonne in liste_index:\n",
    "      continue\n",
    "    if abs(mat_corr_immu.iloc[num_ligne, num_colonne]) > 0.8 :\n",
    "      family[num_ligne].append(liste_actions[num_colonne])\n",
    "      mat_corr.drop([liste_actions[num_colonne]], axis = 'columns', inplace = True)\n",
    "      del liste_index[num_colonne]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QNpUydIUCj2"
   },
   "outputs": [],
   "source": [
    "# Extraction des familles sous forme de DataFrame\n",
    "\n",
    "family2 = []\n",
    "for k in range(41):\n",
    "  if family[k] != []:\n",
    "    family2.append(family[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPDwgiIemJAG"
   },
   "outputs": [],
   "source": [
    "end2 = datetime.datetime(2018,10,31)\n",
    "data = {k:[] for k in range(len(family2))}\n",
    "X = {k:k for k in range(len(family2))}\n",
    "Y = {k:k for k in range(len(family2))}\n",
    "\n",
    "for i in range(len(family2)):\n",
    "  data[i] = pd.concat([prepare(data_cac40[family2[i][j]] , end=end2) for j in range(len(family2[i]))])\n",
    "  data[i] = data_augmentation(data[i])\n",
    "  X[i] = data[i][['MACD', 'RSI', 'STO_K', 'D', '20d-50d', 'momentum']]\n",
    "  Y[i] = data[i][\"Signal\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPHbu6etafEg"
   },
   "source": [
    "## Construction d'un classifieur de *Random Forest* par famille\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NiGdOnOVBhY"
   },
   "source": [
    "On peut désormais construire chacun des classifieurs *Random Forest* : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ix3mm8RuVMrv"
   },
   "outputs": [],
   "source": [
    "#Séparation des données en données d'entrainement(70%) et de données de test(30%) \n",
    "donnee_test = []\n",
    "cac2 = cac.copy()\n",
    "for i in range(len(family2)):\n",
    "  donnee_test.append(train_test_split(X[i], Y[i], test_size=0.3))\n",
    "\n",
    "#Création de la fonction avec Random Forest, une par famille\n",
    "foret_alea = [] #fonction de la famille i à l'indice i\n",
    "y_pred = []\n",
    "for i in range(len(family2)):\n",
    "  clf=RandomForestClassifier(min_samples_leaf = 1, min_samples_split = 2, n_estimators=1500) # n : nombre d'arbres\n",
    "  clf.fit(donnee_test[i][0],donnee_test[i][2])\n",
    "  y_pred.append(clf.predict(donnee_test[i][1]))\n",
    "  # on met à jour le classifier pour les actions correspondantes\n",
    "  for act in family2[i]:\n",
    "    cac2[act] = clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "l-C9KThge-WF",
    "outputId": "62834686-31e8-47a5-d579-769691dd807f"
   },
   "outputs": [],
   "source": [
    "# Exemple pour la famille 1 (indice 0)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(donnee_test[0][3], y_pred[0]))\n",
    "\n",
    "feature_imp = pd.Series(cac['lvmh'].feature_importances_, index = [\"MACD\",'RSI', 'STO_K', \"D\", '20d-50d', 'momentum']).sort_values(ascending=False)\n",
    "\n",
    "#Matrice de confusion \n",
    "\n",
    "m = metrics.confusion_matrix(donnee_test[0][3], y_pred[0])\n",
    "print(\"Matrice de Confusion : \\n\",m)\n",
    "#Ligne : y_test   ; Colonne : y_pred\n",
    "\n",
    "# Mesure l'importance des features avec un histogramme\n",
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "\n",
    "plt.xlabel(\"Scores de l'importance des features dans dans notre modèle\")\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualisation de l'importance des features pour la famille 1\", fontsize=30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nbtYN1ChSgr"
   },
   "source": [
    "Il ne nous reste plus qu'à conserver les classifieurs *Random Forest* dans une table, ce qui nous permettra de les utiliser *a posteriori* afin d'optimiser notre portefeuille d'actions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfyaog0iqvzi"
   },
   "source": [
    "## Présentation des résultats\n",
    "\n",
    "On a maintenant une fonction issue du ML pour chaque famille d'action. \n",
    "\n",
    "Pour une action dans notre portefeuille, on considère la fonction associée à sa famille pour calculer le signal d'achat/vente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBlwsUOCtqXj"
   },
   "outputs": [],
   "source": [
    "def ma_crossover_orders(stocks, famille_fonction, start=end2,end=end):\n",
    "    \"\"\"\n",
    "    :param stocks: liste de tuples (symbol, data brute téléchargée de Yahoo)\n",
    "    :param famille_fonction : Dictionnaire contenant le Classifier de la famille à laquelle appartient l'action en index\n",
    "\n",
    "    :return: pandas DataFrame contenant les ordres à passer\n",
    "    \"\"\"\n",
    "    \n",
    "    trades = pd.DataFrame({\"Price\": [], \"Regime\": [], \"Signal\": []})\n",
    "    for s in stocks:\n",
    "        s_redim = s[1][start:end].copy()\n",
    "        clf = famille_fonction[s[0]]\n",
    "        x = prepare(s_redim,start,end) #50 lignes de moins que s[1][start:end]\n",
    "        x = x[['MACD', 'RSI', 'STO_K', \"D\", '20d-50d','momentum']]\n",
    "        s_redim[\"Prédiction\"] = np.concatenate((50*[-1], clf.predict(x))) #les 50premières dates sont vides à cause de la fct prepare\n",
    "\n",
    "        signals = pd.concat([\n",
    "            pd.DataFrame({\"Price\": s_redim.loc[s_redim[\"Prédiction\"] == 2, \"Adj Close\"],\n",
    "                         \"Regime\": s_redim.loc[s_redim[\"Prédiction\"] == 2, \"Prédiction\"],\n",
    "                         \"Signal\": \"Acheter\"}),\n",
    "            pd.DataFrame({\"Price\": s_redim.loc[s_redim[\"Prédiction\"] == 0, \"Adj Close\"],\n",
    "                         \"Regime\": s_redim.loc[s_redim[\"Prédiction\"] == 0, \"Prédiction\"],\n",
    "                         \"Signal\": \"Vendre\"}),\n",
    "        ])\n",
    "\n",
    "        signals.index = pd.MultiIndex.from_product([signals.index, [s[0]]], names = [\"Date\", \"Symbol\"])\n",
    "        trades = trades.append(signals)\n",
    "\n",
    "    trades.sort_index(inplace = True)\n",
    "    trades.index = pd.MultiIndex.from_tuples(trades.index, names = [\"Date\", \"Symbol\"])\n",
    "\n",
    "    return trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "hv8TR2_whFbW",
    "outputId": "577283b9-3e56-4d39-f5f1-1918b7c7d984"
   },
   "outputs": [],
   "source": [
    "data_cac40[\"lvmh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "tyB0Sl-kq0WN",
    "outputId": "da897445-739c-474e-acff-6d64e890b903"
   },
   "outputs": [],
   "source": [
    "def backtest(stocks, cash,famille_fonction, portfolio = dict(),port_prices = dict()):\n",
    "    \"\"\"\n",
    "    :param stocks: Une liste de tuples (Symbole de l'action, données brutes de Yahoo)\n",
    "    :param cash: integer for starting cash value\n",
    "    :param portfolio: Dictionnaire  nb d'actions détenues à t\n",
    "    :param port_prices: Dictionnaire prix de l'action à t\n",
    "    \n",
    "    :return: pandas DataFrame contenant les ordres à passer\n",
    "\n",
    "    On se servira dans cette fonction de l'historique de la valeur du portefeuille afin de voir comment il évolue dans le temps. \n",
    "    \"\"\"\n",
    "    signals = ma_crossover_orders(stocks,famille_fonction)\n",
    "\n",
    "    # Dataframe qui contiendra les données historiques\n",
    "    results = pd.DataFrame({\"Cash Dispo\": [],\n",
    "                            \"Portfolio Value\": [],\n",
    "                            \"Type\": [],\n",
    "                            \"Nb Action\": [],\n",
    "                            \"Trade Value\": [],\n",
    "                            \"Total Cash\": []})\n",
    "\n",
    "    for index, row in signals.iterrows():\n",
    "\n",
    "        portfolio_val = 0 \n",
    "        for key, val in portfolio.items():\n",
    "            for i,dat in stocks :\n",
    "               if key ==i:\n",
    "                  port_prices[key] = dat.loc[str(index[0].date()),\"Adj Close\"]\n",
    "            portfolio_val += val * port_prices[key]\n",
    "\n",
    "        shares = portfolio[index[1]]\n",
    "        old_price = port_prices[index[1]]\n",
    "        \n",
    "        n_max = np.floor((portfolio_val + cash)/(row[\"Price\"]*len(portfolio)))\n",
    "\n",
    "        if row[\"Signal\"]==\"Acheter\" and shares<n_max : #la deuxième condition évite d'acheter deux fois consécutives\n",
    "            trade_val = (n_max-shares)*row[\"Price\"]\n",
    "            portfolio[index[1]]= n_max\n",
    "            port_prices[index[1]] = (shares*port_prices[index[1]]+(n_max-shares)*row[\"Price\"])/(n_max)\n",
    " \n",
    "            portfolio_val += trade_val\n",
    "            cash -= trade_val\n",
    "\n",
    "            # Update report\n",
    "            results = results.append(pd.DataFrame({\n",
    "                    \"Cash Dispo\":cash,\n",
    "                    \"Portfolio Value\": portfolio_val,\n",
    "                    \"Type\": row[\"Signal\"],\n",
    "                    \"Nb Action\": n_max-shares,\n",
    "                    \"Trade Value\": trade_val,\n",
    "                    \"Total Cash\": cash +portfolio_val\n",
    "                }, index = [index]))\n",
    "\n",
    "        elif row[\"Signal\"]==\"Vendre\" and shares > 0:\n",
    "            trade_val = shares * row[\"Price\"]\n",
    "            portfolio[index[1]]= 0\n",
    "            port_prices[index[1]] = row[\"Price\"]\n",
    "\n",
    "            portfolio_val -= trade_val\n",
    "            cash += trade_val\n",
    "\n",
    "            # Update report\n",
    "            results = results.append(pd.DataFrame({\n",
    "                    \"Cash Dispo\":cash,\n",
    "                    \"Portfolio Value\": portfolio_val,\n",
    "                    \"Type\": row[\"Signal\"],\n",
    "                    \"Nb Action\": shares,\n",
    "                    \"Trade Value\": trade_val,\n",
    "                    \"Total Cash\": cash +portfolio_val\n",
    "                }, index = [index]))\n",
    "\n",
    "        else : pass \n",
    "\n",
    "    results.sort_index(inplace = True)\n",
    "    results.index = pd.MultiIndex.from_tuples(results.index, names = [\"Date\", \"Symbol\"])\n",
    "    return results\n",
    "\n",
    "stocks = [(\"lvmh\",data_cac40['lvmh']),\n",
    "        (\"danone\", data_cac40['danone']),\n",
    "        (\"thales\", data_cac40['thales']),\n",
    "        (\"airbus\", data_cac40['airbus']),\n",
    "        (\"veolia\", data_cac40['veolia']),\n",
    "        (\"vinci\", data_cac40['vinci']),\n",
    "        (\"peugeot\", data_cac40['peugeot']),\n",
    "        (\"capge\", data_cac40['capgemini']),\n",
    "        (\"so_ge\", data_cac40['societegenerale']),\n",
    "        (\"safran\", data_cac40['safran'])]\n",
    "\n",
    "portfolio = {\"lvmh\" : 0, \"danone\" : 0,\"thales\":0, \"airbus\":0,\"veolia\":0,\"vinci\":0,\"peugeot\":0,\"capge\":0,\"so_ge\":0,\"safran\":0}\n",
    "port_prices = {\"lvmh\" : 0, \"danone\" : 0,\"thales\":0, \"airbus\":0,\"veolia\":0,\"vinci\":0,\"peugeot\":0,\"capge\":0,\"so_ge\":0,\"safran\":0}\n",
    "\n",
    "cash = 100000\n",
    "bk_ML_cor = backtest(stocks, cash,cac2, portfolio, port_prices)\n",
    "\n",
    "\n",
    "cash = 100000\n",
    "portfolio = {\"lvmh\" : 0, \"danone\" : 0,\"thales\":0, \"airbus\":0,\"veolia\":0,\"vinci\":0,\"peugeot\":0,\"capge\":0,\"so_ge\":0,\"safran\":0}\n",
    "port_prices = {\"lvmh\" : 0, \"danone\" : 0,\"thales\":0, \"airbus\":0,\"veolia\":0,\"vinci\":0,\"peugeot\":0,\"capge\":0,\"so_ge\":0,\"safran\":0}\n",
    "\n",
    "bk_ML = backtest(stocks, cash,cac, portfolio, port_prices)\n",
    "\n",
    "\n",
    "bk_ML_cor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCQJDckvLNv4"
   },
   "source": [
    "## Graphique des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "T0lhwZ7cBUnS",
    "outputId": "ca7943c3-97ee-4c11-8bf2-732cb006f9f6"
   },
   "outputs": [],
   "source": [
    "d = pd.Timedelta('1 day')\n",
    "cac40 = pdr.get_data_yahoo('^FCHI', start=end3+25*d, end=end)\n",
    "\n",
    "cac40[\"Adj Close\"].apply(lambda x:x/cac40[\"Adj Close\"][0]).plot(grid=True,label = \"CAC 40\").axhline(y = 1, color = \"black\", lw = 2)\n",
    "bk_ML[\"Total Cash\"].groupby(level = 0).apply(lambda x: x[-1]/cash).plot(grid=True,label = \"ML\")\n",
    "bk_ML_cor[\"Total Cash\"].groupby(level = 0).apply(lambda x: x[-1]/cash).plot(grid=True,label = \"ML & Corrélation\")\n",
    "bk_sto[\"Portfolio Value\"].groupby(level = 0).apply(lambda x: x[-1]/cash).plot(grid=True, label = \"Stochastique\")\n",
    "plt.legend()\n",
    "plt.title('Graphique des performances', fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8tQhRRsyp7G"
   },
   "source": [
    "Ce graphique résume l'ensemble de nos résultats. On affiche l'évolution du CAC 40, de nos résultats avec le stochastique, le classifieur sans corrélation et ensuite la méthode avec la corrélation. \n",
    "\n",
    "La méthode des classifieur n'est pas une méthode déterministe, ce qui conduit à une variation faible des résultats. Néanmoins, il en ressort tout le temps la même finalité : la méthode avec le stochastique comme seul indicateur est toujours moins bonne que celle qui combine tous les indicateurs avec le classifieur. Le fait de créer des classifieurs par familles de corrélation permet d'obtenir de meilleurs résultats qu'avec un classifier seul. \n",
    "\n",
    "Enfin, la courbe verte montre que la prise en compte des corrélations permet une meilleure réaction à la chute des cours liée au coronavirus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8XU-zz97SHQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Gestion de portefeuille.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
